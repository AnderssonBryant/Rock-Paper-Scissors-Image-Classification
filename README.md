# Rock-Paper-Scissors-Image-Classification

## Overview

This project is created as a part of the "Belajar Machine Learning untuk Pemula" course by Dicoding. The primary objective is to build an image classification system for the classic game Rock, Paper, Scissors. The project aims to develop a machine learning model capable of accurately identifying and classifying images of hand gestures representing rock, paper, and scissors.

For full project you can visit this link: [KlasifikasiRockPaperScicors](https://colab.research.google.com/drive/1UqIeSHdtjpJb7xPxuxkXr4BQc0679YWK?usp=sharing)

## Features

- Image Classification: Implement a deep learning model to classify hand gesture images into three categories: rock, paper, and scissors.
- Accuracy Metrics: Evaluate and display the model's accuracy on a test dataset, showcasing its performance.

## Technologies Used

- Python: The primary programming language for developing the image classification model.
- TensorFlow/Keras: Utilize deep learning frameworks for building and training the convolutional neural network (CNN).
- Matplotlib: Visualize accuracy metrics and sample predictions.


## Dataset

The dataset used for training the model is sourced from Kaggle. You can access the dataset using the following link:

[Rock-Paper-Scissors Dataset](https://www.kaggle.com/datasets/drgfreeman/rockpaperscissors/data)

The dataset contains labeled images of hand gestures for rock, paper, and scissors.


## License

This project is licensed under the [MIT License](LICENSE).
